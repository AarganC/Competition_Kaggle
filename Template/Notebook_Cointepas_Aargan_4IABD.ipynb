{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from Template_LSTM import LSTM_TEMPLATE as LSTM\n",
    "from Template_ResNet import ResNet_TEMPLATE as ResNet\n",
    "from Template_MLP import MLP\n",
    "from keras.callbacks import TensorBoard\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_param = LSTMtest1\n",
      "name_modele = LSTM\n",
      "batch_size = 512\n",
      "epochs = 70\n",
      "lera = 0.001\n",
      "activation = \n",
      "nb_layer = 5\n",
      "nb_filtre = 32\n",
      "nb_dropout_flag = 1\n",
      "nb_dropout_value = 0.2\n"
     ]
    }
   ],
   "source": [
    "# LSTM ParamTest\n",
    "name_param = \"LSTMtest1\"\n",
    "print(\"name_param = \" + name_param)\n",
    "name_modele = \"LSTM\"\n",
    "print(\"name_modele = \" + name_modele)\n",
    "batch_size = 512\n",
    "print(\"batch_size = \" + str(batch_size))\n",
    "epochs = 70\n",
    "print(\"epochs = \" + str(epochs))\n",
    "lera = 0.001\n",
    "print(\"lera = \" + str(lera))\n",
    "activation = \"\"\n",
    "print(\"activation = \" + str(activation))\n",
    "nb_layer = 5\n",
    "print(\"nb_layer = \" + str(nb_layer))\n",
    "nb_filtre = 32\n",
    "print(\"nb_filtre = \" + str(nb_filtre))\n",
    "nb_dropout_flag = 1\n",
    "print(\"nb_dropout_flag = \" + str(nb_dropout_flag))\n",
    "nb_dropout_value = 0.2\n",
    "print(\"nb_dropout_value = \" + str(nb_dropout_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_param = ResNettest1\n",
      "name_modele = ResNet\n",
      "batch_size = 512\n",
      "epochs = 70\n",
      "lera = 0.001\n",
      "activation = relu\n",
      "nb_layer = 3\n",
      "nb_filtre = \n",
      "nb_dropout_flag = 1\n",
      "nb_dropout_value = 0.2\n"
     ]
    }
   ],
   "source": [
    "# ResNet ParamTest\n",
    "name_param = \"ResNettest1\"\n",
    "print(\"name_param = \" + name_param)\n",
    "name_modele = \"ResNet\"\n",
    "print(\"name_modele = \" + name_modele)\n",
    "batch_size = 512\n",
    "print(\"batch_size = \" + str(batch_size))\n",
    "epochs = 70\n",
    "print(\"epochs = \" + str(epochs))\n",
    "lera = 0.001\n",
    "print(\"lera = \" + str(lera))\n",
    "activation = \"relu\"\n",
    "print(\"activation = \" + activation)\n",
    "nb_layer = 3\n",
    "print(\"nb_layer = \" + str(nb_layer))\n",
    "nb_filtre = \"\"\n",
    "print(\"nb_filtre = \" + str(nb_filtre))\n",
    "nb_dropout_flag = 1\n",
    "print(\"nb_dropout_flag = \" + str(nb_dropout_flag))\n",
    "nb_dropout_value = 0.2\n",
    "print(\"nb_dropout_value = \" + str(nb_dropout_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/tensorflowlatest/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15750, 32, 32, 3)\n",
      "(1750, 32, 32, 3)\n",
      "Tensor(\"input_1:0\", shape=(?, 32, 32, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "train_csv = pd.read_csv('../Data/data/train.csv')\n",
    "\n",
    "filenames = ['../Data/data/train/' + fname for fname in train_csv['id'].tolist()]\n",
    "labels = train_csv['has_cactus'].tolist()\n",
    "\n",
    "train = []\n",
    "for file_name in filenames:\n",
    "    img = cv2.imread(file_name)\n",
    "    img = img.reshape(32*32*3,)\n",
    "    img = img/255\n",
    "    train.append(img)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train,\n",
    "                                                    labels,\n",
    "                                                    train_size=0.9)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = np.reshape(x_train, (-1, 32, 32, 3))\n",
    "print(x_train.shape)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (-1, 32, 32, 3))\n",
    "print(x_test.shape)\n",
    "\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "print(inputs)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet ResNettest1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   1040        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   1088        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   4160        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  8320        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   8256        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 128)  8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   8256        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 128)  8320        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 128)    16512       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 256)    33024       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    33024       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 128)    32896       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 256)    33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           add_7[0][0]                      \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    32896       batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    33024       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 256)    0           add_8[0][0]                      \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 256)    0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            514         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 846,946\n",
      "Trainable params: 841,730\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Preaparation mod√®le\n",
    "if name_modele == \"LSTM\":\n",
    "    print(name_modele + \" \" + name_param)\n",
    "    outputs = LSTM(inputs, nb_filtre, nb_layer, nb_dropout_flag, nb_dropout_value)\n",
    "if name_modele == \"ResNet\":\n",
    "    print(name_modele + \" \" + name_param)\n",
    "    outputs = ResNet(nb_layer, inputs, activation, nb_dropout_flag, nb_dropout_value)\n",
    "if name_modele == \"MLP\":\n",
    "    outputs = MLP(inputs, activation, nb_layer, nb_filtre)\n",
    "\n",
    "## Run model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "if name_modele == 'MLP':\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=float(lera)),\n",
    "                  metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=float(lera)),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'res_logs')\n",
    "date = datetime.today()\n",
    "year = date.strftime(\"%Y\")\n",
    "month = date.strftime(\"%m\")\n",
    "day = date.strftime(\"%d\")\n",
    "hour = date.strftime(\"%H\")\n",
    "minute = date.strftime(\"%M\")\n",
    "model_name = \"{}{}{}{}{}{}{}_es{}_lr{}_bs{}_{}_ly{}_nf{}\" \\\n",
    "    .format(name_param, name_modele, year, month, day, hour, minute, epochs, lera, batch_size, activation, nb_layer, nb_filtre)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "callbacks = TensorBoard(log_dir=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15750 samples, validate on 1750 samples\n",
      "Epoch 1/1\n",
      "15750/15750 [==============================] - 545s 35ms/step - loss: 0.7541 - acc: 0.9369 - val_loss: 0.8231 - val_acc: 0.8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10aa7c6a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=int(batch_size),\n",
    "          epochs=int(1), #int(epochs)\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# predicted class\n",
    "filenames_test = ['../Data/data/test/' + f for f in listdir('../Data/data/test/') if isfile(join('../Data/data/test/', f))]\n",
    "print(len(filenames_test))\n",
    "test = []\n",
    "i = 0\n",
    "for file_name in filenames_test:\n",
    "    img = cv2.imread(file_name)\n",
    "    # print(\"--------------------------------------------------------------------------------------------------\"+str(i)+str(img))\n",
    "    # i=i+1\n",
    "    img = img.reshape(32 * 32 * 3, )\n",
    "    img = img / 255\n",
    "    test.append(img)\n",
    "test = np.array(test)\n",
    "test = np.reshape(test, (-1, 32, 32, 3))\n",
    "pred1 = model.predict(test)\n",
    "predf = pred1.argmax(axis=-1)\n",
    "print(predf)\n",
    "# np.savetxt(\"predict.csv\", np.c_[filenames_test,predf], delimiter=\",\")\n",
    "df = pd.DataFrame({\"id\": filenames_test, \"has_cactus\": predf})\n",
    "df.to_csv(\"./prediction/predict_{}_{}.csv\".format(name_modele, name_param), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense, concatenate\n",
    "from keras.layers import multiply, add\n",
    "from keras.layers import Input\n",
    "\n",
    "def LSTM_TEMPLATE (inputs, nb_filtre, nb_layer, dropout_flag, dropout_value):\n",
    "    nb_filtre = int(nb_filtre)\n",
    "    nb_filtre_b = nb_filtre*2\n",
    "\n",
    "    print(nb_filtre)\n",
    "    print(nb_filtre_b)\n",
    "\n",
    "    x = Conv2D(nb_filtre,\n",
    "               kernel_size=3,\n",
    "               strides=1,\n",
    "               padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    for i in range(int(nb_layer)):\n",
    "        # Layer 1\n",
    "        C = Conv2D(nb_filtre_b,\n",
    "                   kernel_size=3,\n",
    "                   strides=1,\n",
    "                   padding='same')(x)\n",
    "        C = BatchNormalization()(C)\n",
    "\n",
    "        H = Conv2D(nb_filtre,\n",
    "                   kernel_size=3,\n",
    "                   strides=1,\n",
    "                   padding='same')(x)\n",
    "        H = BatchNormalization()(H)\n",
    "\n",
    "        Hx = concatenate([H, x])\n",
    "        F = Activation('sigmoid')(Hx)\n",
    "\n",
    "        I = Activation('sigmoid')(Hx)\n",
    "        L = Activation('tanh')(Hx)\n",
    "        IL = multiply([I, L])\n",
    "\n",
    "        C = multiply([C, F])\n",
    "        C = add([C, IL])\n",
    "\n",
    "        C = Activation('tanh')(C)\n",
    "        O = Activation('sigmoid')(Hx)\n",
    "        x = multiply([C, O])\n",
    "\n",
    "        nb_filtre_b = nb_filtre_b + nb_filtre\n",
    "\n",
    "    outputs = Conv2D(nb_filtre,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same')(x)\n",
    "\n",
    "    x = BatchNormalization()(outputs)\n",
    "\n",
    "    if dropout_flag == 1 or dropout_flag == 4 or dropout_flag == 5 or dropout_flag == 7:\n",
    "        x = Dropout(dropout_value)(x)\n",
    "\n",
    "    x = keras.layers.add([x, outputs])\n",
    "\n",
    "    y = Flatten()(x)\n",
    "\n",
    "    if dropout_flag == 2 or dropout_flag == 4 or dropout_flag == 6 or dropout_flag == 7:\n",
    "        y = Dropout(dropout_value)(y)\n",
    "\n",
    "    outputs = Dense(2, activation='softmax')(y)\n",
    "\n",
    "    if dropout_flag == 3 or dropout_flag == 5 or dropout_flag == 6 or dropout_flag == 7:\n",
    "        outputs = Dropout(dropout_value)(outputs)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, AveragePooling2D, Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# -----------------\n",
    "#           |\n",
    "# Model     |  n\n",
    "#           |v1(v2)\n",
    "# -----------------\n",
    "# ResNet20  | 3 (2)\n",
    "# ResNet32  | 5(NA)\n",
    "# ResNet44  | 7(NA)\n",
    "# ResNet56  | 9 (6)\n",
    "# ResNet110 |18(12)\n",
    "# ResNet164 |27(18)\n",
    "# ResNet1001| (111)\n",
    "# -----------------\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def ResNet_TEMPLATE(n, inputs, activation, dropout_flag, dropout_value):\n",
    "    num_filters_in = 16\n",
    "    num_classes = 2\n",
    "    # Start model definition.\n",
    "\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(int(n)):\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if dropout_flag == 1 or dropout_flag == 4 or dropout_flag == 5 or dropout_flag == 7:\n",
    "        x = Dropout(dropout_value)(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    if dropout_flag == 2 or dropout_flag == 4 or dropout_flag == 6 or dropout_flag == 7:\n",
    "        y = Dropout(dropout_value)(y)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    if dropout_flag == 3 or dropout_flag == 5 or dropout_flag == 6 or dropout_flag == 7:\n",
    "        outputs = Dropout(dropout_value)(outputs)\n",
    "    return outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
